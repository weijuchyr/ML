{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl0OH3XGTXe1"
   },
   "source": [
    "# HW5 Skeleton Code\n",
    "Please note that this skeleton code is provided to help you with homework.\n",
    "Full description of each question can be found on HW5.pdf, so please read instruction of each question carefully. There might be some questions that is not presented in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "1QYqL7lvuvmK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awc_PHjUuvmR"
   },
   "source": [
    "## Q. Changing HTML Text to Plain Text\n",
    "\n",
    "The Python library <b>BeautifulSoup</b> is useful for dealing with html text. In order to use this library, you will need to install it first by running the following command: \n",
    " <b>conda install beautifulsoup4</b> \n",
    " in the terminal.\n",
    " <br> In the code, you can import it by running the following line: \n",
    "<br> \n",
    "  <b>from bs4 import BeautifulSoup </b>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JaHFZFOuuvmU"
   },
   "outputs": [],
   "source": [
    "  #Read our data file\n",
    "df_train = pd.read_csv(r'stack_stats_2023_train.csv') #Todo\n",
    "df_test = pd.read_csv(r'stack_stats_2023_test.csv') #Todo\n",
    "#df_train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jzyC4JZpuvmW"
   },
   "outputs": [],
   "source": [
    "#Cleaning 'Body'\n",
    "#Change HTML Text to Plain text using get_text() function from BeautifulSoup\n",
    "#If you are not familiar with the apply method, please check discussion week 10 lecture and code.\n",
    "\n",
    "#Manually cleaned up newline tag \\n and tab tag \\t.\n",
    "df_train['Body'] = df_train['Body'].apply(lambda x: BeautifulSoup(x).get_text().replace('/n', '').replace('/t', '')) #Todo\n",
    "\n",
    "#Cleaning Tags\n",
    "#This would be somewhat similar to the above.\n",
    "#Manually cleaned up newline tag \\n and tab tag \\t.\n",
    "df_train['Tags'] = df_train['Tags'].apply(lambda x: BeautifulSoup(x).get_text().replace('/n', '').replace('/t', ''))\n",
    "\n",
    "\n",
    "#Todo: Repeat the same process for test dataset \n",
    "df_test['Body'] = df_test['Body'].apply(lambda x: BeautifulSoup(x).get_text().replace('/n', '').replace('/t', ''))\n",
    "df_test['Tags'] = df_test['Tags'].apply(lambda x: BeautifulSoup(x).get_text().replace('/n', '').replace('/t', ''))\n",
    "\n",
    "\n",
    "#df_train['Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNS-3DkCuvmb"
   },
   "source": [
    "## Q. Basic Text Cleaning and Merging into a single Text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "031sBi5Duvmc"
   },
   "source": [
    "### Change to Lower Case, Remove puncuation, digits, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "t-YUYKlvuvmd"
   },
   "outputs": [],
   "source": [
    "#Change to Lowercase\n",
    "\n",
    "df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].applymap(lambda x: x.lower()) #Todo, do you see why we used applymap instead of apply in this case? \n",
    "df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].applymap(lambda x: x.lower()) #Todo\n",
    "\n",
    "#df_train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Bbcp_w_wuvme"
   },
   "outputs": [],
   "source": [
    "#Remove Punctations \n",
    "from string import punctuation\n",
    "\n",
    "#You can get this function from our discussion session code. However, we leave it as a blank for a practice.\n",
    "def remove_punctuation(document):\n",
    "    \n",
    "    no_punct = ''.join([character for character in document if character not in punctuation])#Todo\n",
    "\n",
    "    return no_punct\n",
    "\n",
    "df_train['Body'] = df_train['Body'].apply(remove_punctuation)\n",
    "df_train['Title'] = df_train['Title'].apply(remove_punctuation)\n",
    "df_train['Tags'] = df_train['Tags'].apply(remove_punctuation)\n",
    "df_test['Body'] = df_test['Body'].apply(remove_punctuation)\n",
    "df_test['Title'] = df_test['Title'].apply(remove_punctuation)\n",
    "df_test['Tags'] = df_test['Tags'].apply(remove_punctuation)\n",
    "# df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].apply(remove_punctuation)#Todo \n",
    "# df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].apply(remove_punctuation)#Todo\n",
    "\n",
    "# df_train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "yNUiymSJuvmh"
   },
   "outputs": [],
   "source": [
    "#Remove Digits \n",
    "\n",
    "def remove_digit(document): \n",
    "    \n",
    "    no_digit = ''.join([character for character in document if not character.isdigit()])#Todo\n",
    "              \n",
    "    return no_digit\n",
    "\n",
    "df_train['Body'] = df_train['Body'].apply(remove_digit)\n",
    "df_train['Title'] = df_train['Title'].apply(remove_digit)\n",
    "df_train['Tags'] = df_train['Tags'].apply(remove_digit)\n",
    "df_test['Body'] = df_test['Body'].apply(remove_digit)\n",
    "df_test['Title'] = df_test['Title'].apply(remove_digit)\n",
    "df_test['Tags'] = df_test['Tags'].apply(remove_digit)\n",
    "\n",
    "# df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].apply(remove_digit)#Todo \n",
    "# df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].apply(remove_digit)#Todo\n",
    "\n",
    "# df_train['Title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAsCQQPQuvmi"
   },
   "source": [
    "### Tokenization and Remove Stopwords and do stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25821,
     "status": "ok",
     "timestamp": 1668123057199,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "gOrVZxXQuvmj",
    "outputId": "07dd90e0-e5ca-4634-f43f-f379fe3a0787"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "df_train['Body'] = df_train['Body'].apply(word_tokenize)\n",
    "df_train['Title'] = df_train['Title'].apply(word_tokenize)\n",
    "df_train['Tags'] = df_train['Tags'].apply(word_tokenize)\n",
    "df_test['Body'] = df_test['Body'].apply(word_tokenize)\n",
    "df_test['Title'] = df_test['Title'].apply(word_tokenize)\n",
    "df_test['Tags'] = df_test['Tags'].apply(word_tokenize)\n",
    "# df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].apply(word_tokenize)#Todo \n",
    "# df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].apply(word_tokenize)#Todo\n",
    "\n",
    "# df_train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2684,
     "status": "ok",
     "timestamp": 1668123197885,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "82DJNdV1uvmj",
    "outputId": "8f8148ae-7551-43fc-d3d3-2bc8d8202d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(document):\n",
    "    \n",
    "    words = [word for word in document if not word in stop_words]#Todo\n",
    "    \n",
    "    return words\n",
    "\n",
    "df_train['Body'] = df_train['Body'].apply(remove_stopwords)\n",
    "df_train['Title'] = df_train['Title'].apply(remove_stopwords)\n",
    "df_train['Tags'] = df_train['Tags'].apply(remove_stopwords)\n",
    "df_test['Body'] = df_test['Body'].apply(remove_stopwords)\n",
    "df_test['Title'] = df_test['Title'].apply(remove_stopwords)\n",
    "df_test['Tags'] = df_test['Tags'].apply(remove_stopwords)\n",
    "# df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].apply(remove_stopwords)#Todo\n",
    "# df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].apply(remove_stopwords)#Todo\n",
    "\n",
    "# df_train['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "54S-irnRuvmk"
   },
   "outputs": [],
   "source": [
    "#We use porter stemming \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemmer(document):\n",
    "    \n",
    "    stemmed_document = [porter.stem(word) for word in document] #Todo\n",
    "    \n",
    "    return stemmed_document\n",
    "\n",
    "df_train['Body'] = df_train['Body'].apply(stemmer)\n",
    "df_train['Title'] = df_train['Title'].apply(stemmer)\n",
    "df_train['Tags'] = df_train['Tags'].apply(stemmer)\n",
    "df_test['Body'] = df_test['Body'].apply(stemmer)\n",
    "df_test['Title'] = df_test['Title'].apply(stemmer)\n",
    "df_test['Tags'] = df_test['Tags'].apply(stemmer)\n",
    "# df_train[['Body','Title','Tags']] = df_train[['Body','Title','Tags']].apply(stemmer) #Todo\n",
    "# df_test[['Body','Title','Tags']] = df_test[['Body','Title','Tags']].apply(stemmer) #Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2sfBcaMLTok"
   },
   "source": [
    "## Let's Check our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "r6V33S7pLS76"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, master, student, eec, work, way, toward, ...</td>\n",
       "      <td>[pytorch, tutori, dqn, defin, state, differ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>[know, good, question, found, answer, anywher,...</td>\n",
       "      <td>[random, walk, memori]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>[time, repeat, fold, crossvalid, want, report,...</td>\n",
       "      <td>[statist, report, repeat, crossvalid]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>[dataset, mm, record, around, featur, class, i...</td>\n",
       "      <td>[binari, classif, imbalanc, data, odd, calibr,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>[want, run, regress, one, explanatori, variabl...</td>\n",
       "      <td>[best, summar, likert, data, use, independ, va...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  [im, master, student, eec, work, way, toward, ...   \n",
       "1  477291      1  [know, good, question, found, answer, anywher,...   \n",
       "2  448489      4  [time, repeat, fold, crossvalid, want, report,...   \n",
       "3  487075      0  [dataset, mm, record, around, featur, class, i...   \n",
       "4  481670      2  [want, run, regress, one, explanatori, variabl...   \n",
       "\n",
       "                                               Title Tags  \n",
       "0       [pytorch, tutori, dqn, defin, state, differ]   []  \n",
       "1                             [random, walk, memori]   []  \n",
       "2              [statist, report, repeat, crossvalid]   []  \n",
       "3  [binari, classif, imbalanc, data, odd, calibr,...   []  \n",
       "4  [best, summar, likert, data, use, independ, va...   []  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFgV2VL0uvml"
   },
   "source": [
    "### Q. Treat Three text data independently and merge into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "VCB-voc_uvmm"
   },
   "outputs": [],
   "source": [
    "#Treat Three types of data independently\n",
    "#let's define functions that will help this operation\n",
    "def add_body(document):\n",
    "    \n",
    "    string = '_body'\n",
    "    added_document = [x + string for x in document]\n",
    "  \n",
    "    return added_document\n",
    "\n",
    "def add_title(document):\n",
    "    \n",
    "    string = '_title'\n",
    "    added_document = [x + string for x in document]\n",
    "  \n",
    "    return added_document\n",
    "\n",
    "def add_tags(document):\n",
    "    \n",
    "    string = '_tags'\n",
    "    added_document = [x + string for x in document]\n",
    "  \n",
    "    return added_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UWy0BGVHuvmm"
   },
   "outputs": [],
   "source": [
    "df_train['Body'] = df_train['Body'].apply(lambda x: add_body(x))\n",
    "df_train['Title'] = df_train['Title'].apply(lambda x: add_title(x))\n",
    "df_train['Tags'] = df_train['Tags'].apply(lambda x: add_tags(x))\n",
    "\n",
    "df_test['Body'] = df_test['Body'].apply(lambda x: add_body(x))\n",
    "df_test['Title'] = df_test['Title'].apply(lambda x: add_title(x))\n",
    "df_test['Tags'] = df_test['Tags'].apply(lambda x: add_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we need to merge all those 3 columns into a single column. Implement this below.\n",
    "df_train['text'] = df_train['Body'] + df_train['Title'] + df_train['Tags']#Todo\n",
    "df_test['text'] = df_test['Body'] + df_test['Title'] + df_test['Tags']#Todo\n",
    "\n",
    "# print(df_test['text'])\n",
    "# len(df_test['text'].axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq2PYhnmLhDi"
   },
   "source": [
    "## Let's check our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "rtYP_Lu3LjIb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "      <td>[pytorch_title, tutori_title, dqn_title, defin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "      <td>[random_title, walk_title, memori_title]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "      <td>[statist_title, report_title, repeat_title, cr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "      <td>[binari_title, classif_title, imbalanc_title, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "      <td>[best_title, summar_title, likert_title, data_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  [im_body, master_body, student_body, eec_body,...   \n",
       "1  477291      1  [know_body, good_body, question_body, found_bo...   \n",
       "2  448489      4  [time_body, repeat_body, fold_body, crossvalid...   \n",
       "3  487075      0  [dataset_body, mm_body, record_body, around_bo...   \n",
       "4  481670      2  [want_body, run_body, regress_body, one_body, ...   \n",
       "\n",
       "                                               Title Tags  \\\n",
       "0  [pytorch_title, tutori_title, dqn_title, defin...   []   \n",
       "1           [random_title, walk_title, memori_title]   []   \n",
       "2  [statist_title, report_title, repeat_title, cr...   []   \n",
       "3  [binari_title, classif_title, imbalanc_title, ...   []   \n",
       "4  [best_title, summar_title, likert_title, data_...   []   \n",
       "\n",
       "                                                text  \n",
       "0  [im_body, master_body, student_body, eec_body,...  \n",
       "1  [know_body, good_body, question_body, found_bo...  \n",
       "2  [time_body, repeat_body, fold_body, crossvalid...  \n",
       "3  [dataset_body, mm_body, record_body, around_bo...  \n",
       "4  [want_body, run_body, regress_body, one_body, ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4esXb6WGuvmo"
   },
   "source": [
    "### Q. Detokenize and convert to document term matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JwhJ1pVBuvmo"
   },
   "outputs": [],
   "source": [
    "#Merge Three text column into one column and detokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_train = df_train['text'].apply(TreebankWordDetokenizer().detokenize) #Todo: Detokenize your tokenized text data\n",
    "countvec_train = CountVectorizer(min_df=0.005)\n",
    "countvec = CountVectorizer(min_df=0.005) #Todo: Define your own CountVectorizer here\n",
    "sparse_dtm_train = countvec_train.fit_transform(text_train) #Todo: Fit and Transform your Countvectorizer and return sparse dtm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VoO-e-00uvmo"
   },
   "outputs": [],
   "source": [
    "#Todo: Do same on the test set.\n",
    "text_test = df_test['text'].apply(TreebankWordDetokenizer().detokenize)\n",
    "sparse_dtm_test = countvec.fit_transform(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1668128857596,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "hiK01v4luvmp",
    "outputId": "f6521cdc-fd1a-446f-9a7c-eb03df04a5f2"
   },
   "outputs": [],
   "source": [
    "#Convert the sprase dtm to pandas DataFrame.\n",
    "dtm_train = pd.DataFrame(sparse_dtm_train.toarray(), columns=countvec_train.get_feature_names(), index=text_train.index)\n",
    "dtm_test = pd.DataFrame(sparse_dtm_test.toarray(), columns=countvec.get_feature_names(), index=text_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine the train_DTM and test_DTM together, using inner join to exclude features that only appear in one DTM.\n",
    "dtm = pd.concat([dtm_train, dtm_test], join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate the new train_DTM and test_DTM from the combined DTM.\n",
    "new_dtm_train = dtm.iloc[0:dtm_train.shape[0]]\n",
    "new_dtm_test = dtm.iloc[dtm_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZVDS6druvmq"
   },
   "source": [
    "### Q. Change dependent variable to binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "DSQu_SPquvmq"
   },
   "outputs": [],
   "source": [
    "#Change 'Score' to a binary variable, which indicates whether the question is good or not.\n",
    "y_train = np.where(df_train['Score'] >= 1, 1, 0) #Todo\n",
    "y_test = np.where(df_test['Score'] >= 1, 1, 0) #Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kWhfmKlYuvmr"
   },
   "outputs": [],
   "source": [
    "#Add y_train and y_test to your data frame if it is needed. Drop unnecessary columns\n",
    "df_train['good_question'] = y_train\n",
    "df_test['good_question'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns=['good_question'], inplace=True)\n",
    "df_test.drop(columns=['good_question'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiYas_A6JcS1"
   },
   "source": [
    "## Let's check our DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WeTgM0ZMJqbI"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Score</th>\n",
       "      <th>Body</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502641</td>\n",
       "      <td>1</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "      <td>[pytorch_title, tutori_title, dqn_title, defin...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[im_body, master_body, student_body, eec_body,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>477291</td>\n",
       "      <td>1</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "      <td>[random_title, walk_title, memori_title]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[know_body, good_body, question_body, found_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>448489</td>\n",
       "      <td>4</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "      <td>[statist_title, report_title, repeat_title, cr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[time_body, repeat_body, fold_body, crossvalid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487075</td>\n",
       "      <td>0</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "      <td>[binari_title, classif_title, imbalanc_title, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[dataset_body, mm_body, record_body, around_bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>481670</td>\n",
       "      <td>2</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "      <td>[best_title, summar_title, likert_title, data_...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[want_body, run_body, regress_body, one_body, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id  Score                                               Body  \\\n",
       "0  502641      1  [im_body, master_body, student_body, eec_body,...   \n",
       "1  477291      1  [know_body, good_body, question_body, found_bo...   \n",
       "2  448489      4  [time_body, repeat_body, fold_body, crossvalid...   \n",
       "3  487075      0  [dataset_body, mm_body, record_body, around_bo...   \n",
       "4  481670      2  [want_body, run_body, regress_body, one_body, ...   \n",
       "\n",
       "                                               Title Tags  \\\n",
       "0  [pytorch_title, tutori_title, dqn_title, defin...   []   \n",
       "1           [random_title, walk_title, memori_title]   []   \n",
       "2  [statist_title, report_title, repeat_title, cr...   []   \n",
       "3  [binari_title, classif_title, imbalanc_title, ...   []   \n",
       "4  [best_title, summar_title, likert_title, data_...   []   \n",
       "\n",
       "                                                text  \n",
       "0  [im_body, master_body, student_body, eec_body,...  \n",
       "1  [know_body, good_body, question_body, found_bo...  \n",
       "2  [time_body, repeat_body, fold_body, crossvalid...  \n",
       "3  [dataset_body, mm_body, record_body, around_bo...  \n",
       "4  [want_body, run_body, regress_body, one_body, ...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVPT48NRuvms"
   },
   "source": [
    "## (b) Please read the instruction carefully in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3yD6xH8PzyoZ"
   },
   "outputs": [],
   "source": [
    "x_train = new_dtm_train\n",
    "x_test = new_dtm_test\n",
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "# y_train = df_train['good_question'].astype('int32')\n",
    "# x_train = dtm_train\n",
    "\n",
    "# y_test = df_train['good_question'].astype('int32')\n",
    "# x_test = dtm_test\n",
    "\n",
    "# len(x_test.axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=88)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(random_state=88)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2509 1621]\n",
      " [1993 2126]]\n",
      "0.5618862892471814\n",
      "0.5161446953143967\n",
      "0.3924939467312349\n"
     ]
    }
   ],
   "source": [
    "# y_prob = logreg.predict(x_test)\n",
    "y_prob = logreg.predict_proba(x_test)\n",
    "# Convert numpy array to Pandas DataFrame\n",
    "y_test_df = pd.DataFrame(y_prob)\n",
    "y_pred = pd.Series([1 if x > 0.5 else 0 for x in y_prob[:,1]], index=y_test_df.index)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "log_cm = confusion_matrix(y_test, y_pred)\n",
    "log_acc = accuracy_score(y_test, y_pred)\n",
    "log_TPR = (log_cm.ravel()[3])/(log_cm.ravel()[2]+log_cm.ravel()[3])\n",
    "log_FPR = (log_cm.ravel()[1])/(log_cm.ravel()[0]+log_cm.ravel()[1])\n",
    "\n",
    "print(log_cm)\n",
    "print(log_acc)\n",
    "print(log_TPR)\n",
    "print(log_FPR)\n",
    "#log_PRE\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print (\"Confusion Matrix: \\n\", cm)\n",
    "# print (\"\\nAccuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print (\"TPR:\", (cm.ravel()[3])/(cm.ravel()[2]+cm.ravel()[3]))\n",
    "# print (\"FPR:\", (cm.ravel()[1])/(cm.ravel()[0]+cm.ravel()[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrCM_96Quvm2"
   },
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at top 1 questions: 0.000\n",
      "Accuracy at top 2 questions: 0.000\n",
      "Accuracy at top 3 questions: 0.333\n",
      "Accuracy at top 4 questions: 0.500\n",
      "Accuracy at top 5 questions: 0.600\n",
      "Accuracy at top 6 questions: 0.667\n",
      "Accuracy at top 7 questions: 0.714\n",
      "Accuracy at top 8 questions: 0.750\n",
      "Accuracy at top 9 questions: 0.778\n",
      "Accuracy at top 10 questions: 0.800\n",
      "Accuracy at top 11 questions: 0.818\n",
      "Accuracy at top 12 questions: 0.833\n",
      "Accuracy at top 13 questions: 0.846\n",
      "Accuracy at top 14 questions: 0.857\n",
      "Accuracy at top 15 questions: 0.867\n",
      "Accuracy of original order: 0.533\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for the test set using the best model\n",
    "y_pred_prob = logreg.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# sort the questions by predicted probability of usefulness\n",
    "sorted_indices = y_pred_prob.argsort()[::-1]\n",
    "\n",
    "# calculate precision at various cutoff points\n",
    "for i in range(1, 16):\n",
    "    acc = accuracy_score(y_test[sorted_indices][:i], np.ones(i))\n",
    "    print(f\"Accuracy at top {i} questions: {acc:.3f}\")\n",
    "\n",
    "# calculate precision of showing the 15 most recent questions in their original order\n",
    "original_order_accuracy = accuracy_score(y_test[:15], np.ones(15))\n",
    "print(f\"Accuracy of original order: {original_order_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1AHr2NIU61Oco-PfG10o3gAYXLrsyJ8Sv",
     "timestamp": 1668122684758
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
