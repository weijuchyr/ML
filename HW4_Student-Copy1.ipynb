{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gl0OH3XGTXe1"
   },
   "source": [
    "# HW5 Skeleton Code\n",
    "Please note that this skeleton code is provided to help you with homework.\n",
    "Full description of each question can be found on HW5.pdf, so please read instruction of each question carefully. There might be some questions that is not presented in this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1QYqL7lvuvmK"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awc_PHjUuvmR"
   },
   "source": [
    "## Q. Changing HTML Text to Plain Text\n",
    "\n",
    "The Python library <b>BeautifulSoup</b> is useful for dealing with html text. In order to use this library, you will need to install it first by running the following command: \n",
    " <b>conda install beautifulsoup4</b> \n",
    " in the terminal.\n",
    " <br> In the code, you can import it by running the following line: \n",
    "<br> \n",
    "  <b>from bs4 import BeautifulSoup </b>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JaHFZFOuuvmU"
   },
   "outputs": [],
   "source": [
    "  #Read our data file\n",
    "df_train = pd.read_csv(r'stack_stats_2023_train.csv') #Todo\n",
    "df_test = pd.read_csv(r'stack_stats_2023_test.csv') #Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Body = df_train['Body']\n",
    "train_Title = df_train['Title']\n",
    "train_Tags = df_train['Tags']\n",
    "\n",
    "test_Body = df_test['Body']\n",
    "test_Title = df_test['Title']\n",
    "test_Tags = df_test['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jzyC4JZpuvmW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I'm a master's student in EECS working my way ...\n",
       "1        I do not know if this is a good question, but ...\n",
       "2        I am doing 10 times repeated 10-fold cross-val...\n",
       "3        I have a dataset with 1MM records, around 40 f...\n",
       "4        I want to run a regression where one of the ex...\n",
       "                               ...                        \n",
       "19242    I need to fill missing values. I have found th...\n",
       "19243    In the vast majority of cases, linear regressi...\n",
       "19244    I can see on the Wikipedia page of the Poisson...\n",
       "19245    There are three conditions to prove that a fun...\n",
       "19246    I have a timecourse RNASeq experiment for muta...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleaning 'Body'\n",
    "#Change HTML Text to Plain text using get_text() function from BeautifulSoup\n",
    "train_Body = train_Body.apply(lambda x: BeautifulSoup(x).get_text().replace('/n', ''))\n",
    "test_Body = test_Body.apply(lambda x: BeautifulSoup(x).get_text().replace('/n', ''))\n",
    "\n",
    "#Cleaning Tags\n",
    "train_Tags = train_Tags.apply(lambda x: BeautifulSoup(x).get_text().replace('/n', ''))\n",
    "test_Tags = test_Tags.apply(lambda x: BeautifulSoup(x).get_text().replace('/n', ''))\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNS-3DkCuvmb"
   },
   "source": [
    "## Q. Basic Text Cleaning and Merging into a single Text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "031sBi5Duvmc"
   },
   "source": [
    "### Change to Lower Case, Remove puncuation, digits, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "t-YUYKlvuvmd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        i'm a master's student in eecs working my way ...\n",
       "1        i do not know if this is a good question, but ...\n",
       "2        i am doing 10 times repeated 10-fold cross-val...\n",
       "3        i have a dataset with 1mm records, around 40 f...\n",
       "4        i want to run a regression where one of the ex...\n",
       "                               ...                        \n",
       "19242    i need to fill missing values. i have found th...\n",
       "19243    in the vast majority of cases, linear regressi...\n",
       "19244    i can see on the wikipedia page of the poisson...\n",
       "19245    there are three conditions to prove that a fun...\n",
       "19246    i have a timecourse rnaseq experiment for muta...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Change to Lowercase\n",
    "train_Body = train_Body.str.lower()\n",
    "train_Title = train_Title.str.lower()\n",
    "train_Tags = train_Tags.str.lower()\n",
    "\n",
    "test_Body = test_Body.str.lower()\n",
    "test_Title = test_Title.str.lower()\n",
    "test_Tags = test_Tags.str.lower()\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bbcp_w_wuvme"
   },
   "outputs": [],
   "source": [
    "#Remove Punctations \n",
    "from string import punctuation\n",
    "\n",
    "#You can get this function from our discussion session code. However, we leave it as a blank for a practice.\n",
    "def remove_punctuation(document):\n",
    "    \n",
    "    no_punct = ''.join([character for character in document if character not in punctuation])#Todo\n",
    "\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        im a masters student in eecs working my way to...\n",
       "1        i do not know if this is a good question but i...\n",
       "2        i am doing 10 times repeated 10fold crossvalid...\n",
       "3        i have a dataset with 1mm records around 40 fe...\n",
       "4        i want to run a regression where one of the ex...\n",
       "                               ...                        \n",
       "19242    i need to fill missing values i have found tha...\n",
       "19243    in the vast majority of cases linear regressio...\n",
       "19244    i can see on the wikipedia page of the poisson...\n",
       "19245    there are three conditions to prove that a fun...\n",
       "19246    i have a timecourse rnaseq experiment for muta...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body = train_Body.apply(remove_punctuation)\n",
    "train_Title = train_Title.apply(remove_punctuation)\n",
    "train_Tags = train_Tags.apply(remove_punctuation)\n",
    "\n",
    "test_Body = test_Body.apply(remove_punctuation)\n",
    "test_Title = test_Title.apply(remove_punctuation)\n",
    "test_Tags = test_Tags.apply(remove_punctuation)\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yNUiymSJuvmh"
   },
   "outputs": [],
   "source": [
    "#Remove Digits \n",
    "\n",
    "def remove_digit(document): \n",
    "    \n",
    "    no_digit = ''.join([character for character in document if not character.isdigit()])#Todo\n",
    "              \n",
    "    return no_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        im a masters student in eecs working my way to...\n",
       "1        i do not know if this is a good question but i...\n",
       "2        i am doing  times repeated fold crossvalidatio...\n",
       "3        i have a dataset with mm records around  featu...\n",
       "4        i want to run a regression where one of the ex...\n",
       "                               ...                        \n",
       "19242    i need to fill missing values i have found tha...\n",
       "19243    in the vast majority of cases linear regressio...\n",
       "19244    i can see on the wikipedia page of the poisson...\n",
       "19245    there are three conditions to prove that a fun...\n",
       "19246    i have a timecourse rnaseq experiment for muta...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body = train_Body.apply(remove_digit)\n",
    "train_Title = train_Title.apply(remove_digit)\n",
    "train_Tags = train_Tags.apply(remove_digit)\n",
    "\n",
    "test_Body = test_Body.apply(remove_digit)\n",
    "test_Title = test_Title.apply(remove_digit)\n",
    "test_Tags = test_Tags.apply(remove_digit)\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAsCQQPQuvmi"
   },
   "source": [
    "### Tokenization and Remove Stopwords and do stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25821,
     "status": "ok",
     "timestamp": 1668123057199,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "gOrVZxXQuvmj",
    "outputId": "07dd90e0-e5ca-4634-f43f-f379fe3a0787"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [im, a, masters, student, in, eecs, working, m...\n",
       "1        [i, do, not, know, if, this, is, a, good, ques...\n",
       "2        [i, am, doing, times, repeated, fold, crossval...\n",
       "3        [i, have, a, dataset, with, mm, records, aroun...\n",
       "4        [i, want, to, run, a, regression, where, one, ...\n",
       "                               ...                        \n",
       "19242    [i, need, to, fill, missing, values, i, have, ...\n",
       "19243    [in, the, vast, majority, of, cases, linear, r...\n",
       "19244    [i, can, see, on, the, wikipedia, page, of, th...\n",
       "19245    [there, are, three, conditions, to, prove, tha...\n",
       "19246    [i, have, a, timecourse, rnaseq, experiment, f...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body = train_Body.apply(word_tokenize)\n",
    "train_Title = train_Title.apply(word_tokenize)\n",
    "train_Tags = train_Tags.apply(word_tokenize)\n",
    "\n",
    "test_Body = test_Body.apply(word_tokenize)\n",
    "test_Title = test_Title.apply(word_tokenize)\n",
    "test_Tags = test_Tags.apply(word_tokenize)\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2684,
     "status": "ok",
     "timestamp": 1668123197885,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "82DJNdV1uvmj",
    "outputId": "8f8148ae-7551-43fc-d3d3-2bc8d8202d15"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(document):\n",
    "    \n",
    "    words = [word for word in document if not word in stop_words]#Todo\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [im, masters, student, eecs, working, way, tow...\n",
       "1        [know, good, question, found, answer, anywhere...\n",
       "2        [times, repeated, fold, crossvalidation, want,...\n",
       "3        [dataset, mm, records, around, features, class...\n",
       "4        [want, run, regression, one, explanatory, vari...\n",
       "                               ...                        \n",
       "19242    [need, fill, missing, values, found, many, app...\n",
       "19243    [vast, majority, cases, linear, regression, mo...\n",
       "19244    [see, wikipedia, page, poisson, distribution, ...\n",
       "19245    [three, conditions, prove, function, copula, c...\n",
       "19246    [timecourse, rnaseq, experiment, mutants, wt, ...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body = train_Body.apply(remove_stopwords)\n",
    "train_Title = train_Title.apply(remove_stopwords)\n",
    "train_Tags = train_Tags.apply(remove_stopwords)\n",
    "\n",
    "test_Body = test_Body.apply(remove_stopwords)\n",
    "test_Title = test_Title.apply(remove_stopwords)\n",
    "test_Tags = test_Tags.apply(remove_stopwords)\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "54S-irnRuvmk"
   },
   "outputs": [],
   "source": [
    "#We use porter stemming \n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def stemmer(document):\n",
    "    \n",
    "    stemmed_document = [porter.stem(word) for word in document] #Todo\n",
    "    \n",
    "    return stemmed_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [im, master, student, eec, work, way, toward, ...\n",
       "1        [know, good, question, found, answer, anywher,...\n",
       "2        [time, repeat, fold, crossvalid, want, report,...\n",
       "3        [dataset, mm, record, around, featur, class, i...\n",
       "4        [want, run, regress, one, explanatori, variabl...\n",
       "                               ...                        \n",
       "19242    [need, fill, miss, valu, found, mani, approach...\n",
       "19243    [vast, major, case, linear, regress, model, us...\n",
       "19244    [see, wikipedia, page, poisson, distribut, pmf...\n",
       "19245    [three, condit, prove, function, copula, cucv,...\n",
       "19246    [timecours, rnaseq, experi, mutant, wt, compar...\n",
       "Name: Body, Length: 19247, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body = train_Body.apply(stemmer)\n",
    "train_Title = train_Title.apply(stemmer)\n",
    "train_Tags = train_Tags.apply(stemmer)\n",
    "\n",
    "test_Body = test_Body.apply(stemmer)\n",
    "test_Title = test_Title.apply(stemmer)\n",
    "test_Tags = test_Tags.apply(stemmer)\n",
    "\n",
    "train_Body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2sfBcaMLTok"
   },
   "source": [
    "## Let's Check our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "r6V33S7pLS76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [im, master, student, eec, work, way, toward, ...\n",
       "1    [know, good, question, found, answer, anywher,...\n",
       "2    [time, repeat, fold, crossvalid, want, report,...\n",
       "3    [dataset, mm, record, around, featur, class, i...\n",
       "4    [want, run, regress, one, explanatori, variabl...\n",
       "Name: Body, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Body.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hFgV2VL0uvml"
   },
   "source": [
    "### Q. Treat Three text data independently and merge into one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "VCB-voc_uvmm"
   },
   "outputs": [],
   "source": [
    "#Treat Three types of data independently\n",
    "#let's define functions that will help this operation\n",
    "\n",
    "def add_body(document):\n",
    "    \n",
    "    added_document = document.add('Body') #Todo\n",
    "    \n",
    "    return added_document\n",
    "\n",
    "def add_title(document):\n",
    "    \n",
    "    added_document = document.add('Title') #Todo\n",
    "    \n",
    "    return added_document\n",
    "\n",
    "def add_tags(document):\n",
    "    \n",
    "    added_document = document.add('Tags') #Todo\n",
    "    \n",
    "    return added_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UWy0BGVHuvmm"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'add'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-339921c1eae4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_Body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_Title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_Tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_Tags\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_tags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_Body\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_Body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madd_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-29-fc869360ed05>\u001b[0m in \u001b[0;36madd_body\u001b[1;34m(document)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0madd_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0madded_document\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdocument\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Body'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Todo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0madded_document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'add'"
     ]
    }
   ],
   "source": [
    "train_Body = train_Body.apply(add_body)\n",
    "train_Title = train_Title.apply(add_title)\n",
    "train_Tags = train_Tags.apply(add_tags)\n",
    "\n",
    "test_Body = test_Body.apply(add_body)\n",
    "test_Title = test_Title.apply(add_title)\n",
    "test_Tags = test_Tags.apply(add_tags)\n",
    "\n",
    "train_Body\n",
    "\n",
    "#df_train['Body'] = df_train['Body'].apply(add_body)\n",
    "#df_train['Title'] = df_train['Title'].apply(add_title)\n",
    "#df_train['Tags'] = df_train['Tags'].apply(add_tags)\n",
    "\n",
    "#df_test['Body'] = df_test['Body'].apply(add_body)\n",
    "#df_test['Title'] = df_test['Title'].apply(add_title)\n",
    "#df_test['Tags'] = df_test['Tags'].apply(add_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "kgcE1Vcnuvmn"
   },
   "outputs": [],
   "source": [
    "#Now we need to merge all those 3 columns into a single column. Implement this below.\n",
    "#df_train['text'] = df_train[['Body','Title','Tags']].apply(lambda x: pd.DataFrame.join()) #Todo\n",
    "train_files = [train_Body, train_Title, train_Tags]\n",
    "test_files = [test_Body, test_Title, test_Tags]\n",
    "df_train = pd.concat(train_files, axis = 1, join = 'inner')\n",
    "df_test = pd.concat(test_files, axis = 1, join = 'inner') #Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq2PYhnmLhDi"
   },
   "source": [
    "## Let's check our DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtYP_Lu3LjIb"
   },
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4esXb6WGuvmo"
   },
   "source": [
    "### Q. Detokenize and convert to document term matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JwhJ1pVBuvmo"
   },
   "outputs": [],
   "source": [
    "#Merge Three text column into one column and detokenize\n",
    "\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_train = df_train['text'].apply() #Todo: Detokenize your tokenized text data\n",
    "countvec_train = #Todo: Define your own CountVectorizer here\n",
    "sparse_dtm_train = #Todo: Fit and Transform your Countvectorizer and return sparse dtm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VoO-e-00uvmo"
   },
   "outputs": [],
   "source": [
    "#Todo: Do same on the test set.\n",
    "text_test = df_test['text'].apply()\n",
    "sparse_dtm_test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1668128857596,
     "user": {
      "displayName": "Hyungki Im",
      "userId": "11059091126270115149"
     },
     "user_tz": 480
    },
    "id": "hiK01v4luvmp",
    "outputId": "f6521cdc-fd1a-446f-9a7c-eb03df04a5f2"
   },
   "outputs": [],
   "source": [
    "#Convert the sprase dtm to pandas DataFrame.\n",
    "dtm_train = #Todo\n",
    "dtm_test = #Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mZVDS6druvmq"
   },
   "source": [
    "### Q. Change dependent variable to binary variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DSQu_SPquvmq"
   },
   "outputs": [],
   "source": [
    "#Change 'Score' to a binary variable, which indicates whether the question is good or not.\n",
    "y_train = #Todo\n",
    "y_test = #Todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kWhfmKlYuvmr"
   },
   "outputs": [],
   "source": [
    "#Add y_train and y_test to your data frame if it is needed. Drop unnecessary columns\n",
    "df_train[''] = y_train\n",
    "df_test[''] = y_test\n",
    "df_train.drop(columns = [], inplace = True)\n",
    "df_test.drop(columns = [], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiYas_A6JcS1"
   },
   "source": [
    "## Let's check our DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeTgM0ZMJqbI"
   },
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVPT48NRuvms"
   },
   "source": [
    "## (b) Please read the instruction carefully in the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3yD6xH8PzyoZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-O3EsbQGU0uX"
   },
   "outputs": [],
   "source": [
    "#Create Comparison Table\n",
    "#These lines are provided for you to help construct a comparison table.\n",
    "#It is not requred to follow this format. + You need to find ACC, TPR, FPR, PRE for each model that you choose.\n",
    "comparison_data = {'Baseline':[baseline_acc,baseline_TPR,baseline_FPR, baseline_PRE],\n",
    "                   'Logistic Regression':[log_acc,log_TPR,log_FPR, log_PRE],\n",
    "                   'Decision Tree Classifier':[dtc_acc,dtc_TPR,dtc_FPR,dtc_PRE],\n",
    "                   'Random Forest with CV':[rf_acc,rf_TPR, rf_FPR,rf_PRE],\n",
    "                  'Linear Discriminant Analysis':[lda_acc,lda_TPR, lda_FPR,lda_PRE]}\n",
    "\n",
    "comparison_table = pd.DataFrame(data=comparison_data, index=['Accuracy', 'TPR', 'FPR','PRE']).transpose()\n",
    "comparison_table.style.set_properties(**{'font-size': '12pt',}).set_table_styles([{'selector': 'th', 'props': [('font-size', '10pt')]}])\n",
    "comparison_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mjsc7lf6zOms"
   },
   "source": [
    "\n",
    "## Report details of your training procedures and final comparisons on the test set in this cell. Use your best judgment to choose a final model and explain your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XLa-KDajuvmz"
   },
   "source": [
    "## Report Bootstrap Analysis in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrCM_96Quvm2"
   },
   "source": [
    "### (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uh2mvNrrTFBU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1AHr2NIU61Oco-PfG10o3gAYXLrsyJ8Sv",
     "timestamp": 1668122684758
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
